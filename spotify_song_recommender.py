# -*- coding: utf-8 -*-
"""Spotify_Song_Recommender.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u3sczYs9AI8TRE7oSgXv1haRP4_OGEcd

# Initial Setup
"""

# Install specific libraries not included in Colab by default
#!pip install transformers

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import OneHotEncoder, MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity

"""Note: for this line to work, you need to have privously uploated the dataset from kaggle into google collab - under content.

kaggle dataset link:
https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset?resource=download
"""

# Importing Spotify dataset
df = pd.read_csv('/content/dataset.csv')

df.head()

[i for i in df['Unnamed: 0'] if (not isinstance(i, int)) or i > df.shape[0]]

df['Unnamed: 0'].iloc[-1]

df.shape

for i in range(0, df.shape[0]):
  if i != int(df['Unnamed: 0'].iloc[i]):
    print(i)

"""Note: unnamed here is basically another index count for unique tracks. Let's rename it for simplicity to track_index
WE WILL ONLY USE EITHER THE UNNAMED: 0 COLUMN OR THE TRACK ID COLUMN
"""

df.rename(columns={'Unnamed: 0': 'track_index'}, inplace=True)

df.head()

df.columns

# datatype description
df.dtypes

[x for x in df.artists]     # note that sometimes we have double artists separated by commas

[x for x in df.artists if ';' in str(x)]     # You can see those cases here

# all genres are singular however. No lists: each song/track has a single genre
df['track_genre'].unique()

df.artists.unique()

[x for x in df.artists if not isinstance(x, str)]   # 1 nan value exists in artists

# convert artists into lists of artists
# print(df['artists'])
# def artists_to_list(df):
#   # updates artists col from a string separated by ';' into a list of artists.

#   # iterate over the artist col and when you find the semi-colon, do the split

#   # also returns the new df
#   df['artists'] = df['artists'].apply(lambda x: x.split(";"))
#   return df
# artists_to_list(df)
def artist_to_list(s):
  if isinstance(s, str):
    return s.split(";")

df['artists'] = df['artists'].apply(lambda x: artist_to_list(x))

"""# Ignore this"""

# Importing Spotify dataset
# df = pd.read_csv('/content/sample_data/dataset.csv')

# # Try this: downloading from url using wget - probably need more code to fix this
# !pip install wget
# import wget
# df = wget.download("https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset.download")
# # !wget "https://www.kaggle.com/maharshipandya/-spotify-tracks-dataset/download" -O dataset.zip

# kaggle API command: kaggle datasets download -d maharshipandya/-spotify-tracks-dataset

# # see how df looks
# df

"""# Back to our code

Cleaning our data
"""

df.shape

df[df.isnull().any(axis=1)]   # there is exactly 1 row that has NaN values

df = df.dropna()  # let's drop that row from our dataframe

df.shape

"""# TFIDF Vecotrization
This process is done for: track_genre, artists
Everything is first done for genres, then also done for artists
"""

[x for x in df['track_genre'] if not isinstance(x, str)]    # all genre values are strings

# convert all genres to lists (these would be lists of one)
# genre_lists = df['track_genre'].apply(lambda x: x.split(";"))

# genre_lists

# # df['artists'] is already stored as a list, so just make a copy of it
# artist_lists = df[['artists']].copy()
# artist_lists

df['track_genre'] = df['track_genre'].apply(lambda x: [x])  # adds a []
# df['track_genre'] = df['track_genre'].apply(lambda x: x[0]) # removes a []
df['track_genre']

# TFIDF for genres
tfidf = TfidfVectorizer()
genres_tfidf_matrix = tfidf.fit_transform(df['track_genre'].apply(lambda x: " ".join(x)))
genre_df = pd.DataFrame(genres_tfidf_matrix.toarray())
genre_df.columns = ['genre' + "|" + i for i in tfidf.get_feature_names_out()]   # this makes the column heads reflect the genres that they represent
genre_df.reset_index(drop = True, inplace=True)
# df = pd.get_dummies(df, columns=['track_genre'])

# genre df        - note: we don't put this back into the main dataframe
genre_df

# The process for artists would look slightly different as we are passing in a list with multiple elements
# Since artist names may have spaces, we must define a custom tokenizer that uses ';' instead
# We then pass this custom_tokenizer to our tfidf vectorizer
def custom_tokenizer(text):
    return text.split(';')

custom_tfidf = TfidfVectorizer(tokenizer=custom_tokenizer)

# Now let's do TFIDF vectorization for artists
artists_tfidf_matrix = custom_tfidf.fit_transform(df['artists'].apply(lambda x: ";".join(x)))
artists_df = pd.DataFrame(artists_tfidf_matrix.toarray())
artists_df.columns = ['artist' + "|" + i for i in custom_tfidf.get_feature_names_out()]
artists_df.reset_index(drop = True, inplace=True)

# FINALLY!
artists_df

artists_df.shape

# It seems like our code works as we wanted
print(artists_df.columns[artists_df.iloc[0] == 1])
print(artists_df.columns[artists_df.iloc[1] == 1])
print(artists_df.columns[artists_df.iloc[2] != 0])
print()
artists_df[['artist|ingrid michaelson', 'artist|zayn']].iloc[2]

"""# One-hot Encoding"""

df['key']

# code for one-hot encoding here     - add more col names here as needed
# use it on: 'mode', 'key'

# for column in ('mode', 'key'):

def col_ohe(df, column):
  term_freq_col = pd.get_dummies(df[column])
  feature_names = term_freq_col.columns
  term_freq_col.columns = [column + "|" + str(i) for i in feature_names]
  term_freq_col.reset_index(drop=True, inplace=True)
  return term_freq_col


one_hot_mode = col_ohe(df, 'mode')
one_hot_key = col_ohe(df, 'key')

one_hot_key

"""# Drop Unwanted Columns
You can comment or uncomment lines from this to remove different columns from the dataset, if you don't want them
BUT: be sure to edit the code below if you change this part!!!
"""

# Optional line: these lines, uncommented, would remove popularity and explicitness.
# We'll remove the popularity score from our dataset as it quickly changes overtime, and becomes irrelevant
df = df.drop('popularity', axis = 1)
# df = df.drop('explicit', axis = 1)

df.head()

"""# Normalization"""

from sklearn.preprocessing import MinMaxScaler
# note: mode and key are not in this (instead one hot encoded). Should we include time_signature and tempo here or with them?
# we may have dropped popularity or explicitness from the dataset in the previous section
# MAKE SURE: if popularity was/wasn't dropped, it shouldn't/should be here as the first item
# Assuming 'numerical_features' is a list of your numerical column names that only need to be potentially rescaled
numerical_features = ['explicit', 'duration_ms', 'danceability', 'energy',
                      'loudness', 'speechiness', 'acousticness',
                      'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']

scaler = MinMaxScaler()
# df[numerical_features] = scaler.fit_transform(df[numerical_features])

audio = df[numerical_features].reset_index(drop= True)
audio_scaled = pd.DataFrame(scaler.fit_transform(audio), columns = audio.columns)

"""How to deal with 'explicit'
Unlike our other values, this column is made up of booleans. We can either convert it to floats of 0 and 1, or drop it completely
We will go with the first option. But first let's check that it would work okay before alterring the main dataframe
"""

# This would convert explicit values from True and False to 0 and 1
# Done this on a copy so as not to change the actual dataframe
df_copy = df.copy()
df_copy[['explicit']] = scaler.fit_transform(df_copy[['explicit']])
df_copy.head()

df.head()

# [x for x in df['explicit'] if int(x) != df_copy['explicit']]

# This prints nothing meaning that explicit was correctly converted to numerical
for i in range(0, df.shape[0]):
  original_e = df['explicit'].iloc[i]
  new_e = df_copy['explicit'].iloc[i]
  if int(original_e) != new_e:
    print(i, end='    ')
    print(original_e, end='    ')
    print(new_e)

"""Let's convert 'explicit' into a scalar"""

# Added 'explicit' to the numerical_features above, so it would be scaled with everything else
# df[['explicit']] = scaler.fit_transform(df[['explicit']])

df.head()

"""# Miscellaneous
skip while running the main code


Contains:
- list of unique artists
- backend input format
- backend output format
"""

# Get list of all unique artists
# df['artists']
# sum(df['artists'], [])    # This works but take very long - instead, let's use explode()
# if we wanted to use this, we'd apply the set() function on the sum, and then turn that set into a list

artists_copy = df[['artists']].copy()
artists_copy.head()

artists_copy = artists_copy.explode('artists')    # This separates list items into their own rows (look at how row 2 from before turned into 2 rows here)
artists_copy.head()       # We don't need to worry about the multiple indexes

unique_artists = artists_copy['artists'].unique()
print(artists_copy.shape[0])
print(len(unique_artists))
unique_artists

# THE LIST OF UNIQUE ARTISTS
unique_artists = list(unique_artists)
unique_artists

# Output format
# A list/pandas dataframe where each element is a song entry in the recommended playlist
# Cols: 'track_index', 'track_id', 'artists', 'album_name', 'track_name', 'duration_ms', 'explicit', 'danceability', 'energy',
      #  'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature',
      #  'track_genre'
# [[]]

# Input format
# A list where each element is a tuple representing the data for a certain group of attributes. These groups are: [artists, genres, audio_features, key, mode]
# The tuple would be of the form (the_attribute_values, weight)
# The weight is optional, representing how much each value would be considered - must be a float between 0 and 1 OR -1 (default) if the user doesn't choose a weight
  # for artists, the_attribute_values should be a list of all artist names the user has selected (the list may have 1 or multiple elements). The artist names must be the valid string format as found in the dataset - see the unique_artists variable two cells above
  # for genres,  the_attribute_values should be a list of all genres the user has selected (must be valid names from dataset). The list may have 1 or multiple elements
  # for audio_features, this is a list of values for these audio features in this order: 'duration_ms', 'explicit', 'danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature'
    # most of these values have to be floats between 0 and 1, but explicit has to be True or False
  # for key, just 1 value (not a list) - an int between 0 and 11 inclusive. See the graph on right hand for reference: https://en.wikipedia.org/wiki/Pitch_class#Other_ways_to_label_pitch_classes
  # for mode, just 1 value (not a list) - either 0 or 1 - Major is represented by 1 and minor is 0.

# [(artists_data, weight), (genres_data, weight), (audio_features_data, weight), (key_data, weight), (mode_data, weight)]

# Potentially useful reference about different audio features: https://developer.spotify.com/documentation/web-api/reference/get-audio-features

# New: ALTERNATIVE INPUT FORMAT
# Please let me know which one of the input formats you'd be giving me.
# [(artists_data, weight), (genres_data, weight), (audio_feature1_explicit_data, weight), (audio_feature2_duration_ms_data, weight),
#  (audio_feature3_danceability_data, weight), ..., (audio_feature12_time_signature_data, weight), (key_data, weight), (mode_data, weight)]

# In this version, each of the audio features would have a separate tuple for its data(scalar between 0 and 1) and its own individual weight
# audio_features_in_order = ['explicit', 'duration_ms', 'danceability', 'energy',
                  # 'loudness', 'speechiness', 'acousticness',
                  # 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']

# see this for datatypes reference
df.dtypes

"""# ***Combining Everything***"""

# Add all the engineered features in one place - TODO: define function above that would do this but + weights
# final = pd.concat([artists_df, genre_df, audio_scaled, one_hot_key, one_hot_mode], axis = 1)
# final.head()

# Same code as the previous cell but in chuncks so it wouldn't overwork the RAM
# update: this is still too big
# final = artists_df
# final = pd.concat([final, genre_df], axis = 1)
# final = pd.concat([final, audio_scaled], axis = 1)
# final = pd.concat([final, one_hot_key], axis = 1)
# final = pd.concat([final, one_hot_mode], axis = 1)

# Nevermind, this isn't a thing :(
# Same code but this time using append. It would take more time but hopefully less memory
# final = artists_df
# final.append(genre_df, inplace=True)
# final.append(audio_scaled, inplace=True)
# final.append(one_hot_key, inplace=True)
# final.append(one_hot_mode, inplace=True)

# For now, to avoid runtime issues, let's do this without artists_df
final = pd.concat([genre_df, audio_scaled, one_hot_key, one_hot_mode], axis = 1)

final.head()

# Add track ID's / track index
# final['id'] = df['track_index'].values
final.insert(0, 'id', df['track_index'].values)   # This does the same thing but adds it at the beginning

final.head()

"""# Cosine Similarity Function"""

# see below

"""# ***Combining Everything: FUNCTION***

Includes 3 Important functions

- get_final_attributes: Everything we've done to this point (excluding Cosine Similarity section).
- get_ghost_song: make a ghost song using the attributes selected by the user
- use that ghost song to generate recommendations


More details:
- get_final_attributes: This function would do everything we've done in TFIDF Vectorization, one-hot encoding, normalization, and combining everything sections.
It will not take artists into consideration
Returns final (similar to final generated in the *Combining Everything* section)

Other functions here:
- get_final_attributes_and_artists: in progress (hopefully possible). Same as get_final_attributes but final will also include artists
- col_ohe: this is brought from one hot encoding section
- custom_tokenizer: brought from TFIDF section for artists
- todo: update_weights(final_df) --> weighted_final_df
"""

# run this line if you haven't already done so in the one-hot encoding section
def col_ohe(df, column):
  term_freq_col = pd.get_dummies(df[column])
  feature_names = term_freq_col.columns
  term_freq_col.columns = [column + "|" + str(i) for i in feature_names]
  term_freq_col.reset_index(drop=True, inplace=True)
  return term_freq_col

# run this line if you haven't already done so in TFIDF section
def custom_tokenizer(text):   # used for artists only
  return text.split(';')

# def get_final_attributes(df)
def get_final_attributes(df):
  # initial housekeeping
  df.rename(columns={'Unnamed: 0': 'track_index'}, inplace=True)
  df = df.dropna()
  df = df.drop('popularity', axis = 1)

  # TFIDF for genres
  df['track_genre'] = df['track_genre'].apply(lambda x: [x])  # adds a []
  tfidf = TfidfVectorizer()
  genres_tfidf_matrix = tfidf.fit_transform(df['track_genre'].apply(lambda x: " ".join(x)))
  genre_df = pd.DataFrame(genres_tfidf_matrix.toarray())
  genre_df.columns = ['genre' + "|" + i for i in tfidf.get_feature_names_out()]   # this makes the column heads reflect the genres that they represent
  genre_df.reset_index(drop = True, inplace=True)

  # one hot encoding for key and mode
  one_hot_mode = col_ohe(df, 'mode')
  one_hot_key = col_ohe(df, 'key')

  # scaling all attributes
  numerical_features = ['explicit', 'duration_ms', 'danceability', 'energy',
                        'loudness', 'speechiness', 'acousticness', 'instrumentalness',
                        'liveness', 'valence', 'tempo', 'time_signature']

  scaler = MinMaxScaler()
  audio = df[numerical_features].reset_index(drop= True)
  audio_scaled = pd.DataFrame(scaler.fit_transform(audio), columns = audio.columns)

  final = pd.concat([genre_df, audio_scaled, one_hot_key, one_hot_mode], axis = 1)
  return final

# # def get_final_attributes_and_artists(df) (including artists)
# # This is a test that might or might not work
# def get_final_attributes_and_artists(df):
#   # initial housekeeping
#   df.rename(columns={'Unnamed: 0': 'track_index'}, inplace=True)
#   df = df.dropna()
#   df = df.drop('popularity', axis = 1)

#   # TFIDF for genres
#   df['track_genre'] = df['track_genre'].apply(lambda x: [x])  # adds a []
#   tfidf = TfidfVectorizer()
#   genres_tfidf_matrix = tfidf.fit_transform(df['track_genre'].apply(lambda x: " ".join(x)))
#   genre_df = pd.DataFrame(genres_tfidf_matrix.toarray())
#   genre_df.columns = ['genre' + "|" + i for i in tfidf.get_feature_names_out()]   # this makes the column heads reflect the genres that they represent
#   genre_df.reset_index(drop = True, inplace=True)

#   # one hot encoding for key and mode
#   one_hot_mode = col_ohe(df, 'mode')
#   one_hot_key = col_ohe(df, 'key')

#   # scaling all attributes
#   numerical_features = ['explicit', 'duration_ms', 'danceability', 'energy',
#                         'loudness', 'speechiness', 'acousticness', 'instrumentalness',
#                         'liveness', 'valence', 'tempo', 'time_signature']

#   scaler = MinMaxScaler()
#   audio = df[numerical_features].reset_index(drop= True)
#   audio_scaled = pd.DataFrame(scaler.fit_transform(audio), columns = audio.columns)

#   # TFIDF for artists
#   custom_tfidf = TfidfVectorizer(tokenizer=custom_tokenizer)
#   artists_tfidf_matrix = custom_tfidf.fit_transform(df['artists'])
#   artists_df = pd.DataFrame(artists_tfidf_matrix.toarray())
#   artists_df.columns = ['artist' + "|" + i for i in custom_tfidf.get_feature_names_out()]
#   artists_df.reset_index(drop = True, inplace=True)

#   # combine everything

# def get_final_attributes_and_artists(df) (including artists)
# This is a test that might or might not work  ---> It works!!!
def get_final_attributes_and_artists(df):
  # Get everything else but artists
  semifinal = get_final_attributes(df)
  df = df.dropna()

  # TFIDF for artists
  custom_tfidf = TfidfVectorizer(tokenizer=custom_tokenizer)
  artists_tfidf_matrix = custom_tfidf.fit_transform(df['artists'])
  artists_df = pd.DataFrame(artists_tfidf_matrix.toarray())
  artists_df.columns = ['artist' + "|" + i for i in custom_tfidf.get_feature_names_out()]
  artists_df.reset_index(drop = True, inplace=True)

  # combine everything column by column. Insert semifinal to the end of artists_df
  for column_name, column_data in semifinal.items():
    artists_df.insert(len(artists_df.columns), column_name, column_data)

  return artists_df
  # combine everything - ... In Chunks. Code this part if the previous for loop still takes up RAM
  # start with artists_df. Insert a bit of semifinal to the end of artists_df
  # chunk_size =
  # for i in range(0, semifinal.shape[1], chunk_size){}

art_final = get_final_attributes_and_artists(df)

art_final.head()    # Yesss!!!

# Function that adds the weights to final dataframe. The version without artists.
# final would be the output of get_final_attributes
# def add_weights_final_df(final, user_input):
  # Columns order: genre_df, audio_scaled, one_hot_key, one_hot_mode

# Function that adds the weights to final dataframe. The version with artists.
# final would be the output of get_final_attributes_and_artists
def add_weights_final_df_artists(final, user_input):
  song_attributes = [tpl[0] for tpl in user_input]  #using input v2
  song_weights = [tpl[1] for tpl in user_input]  #using input v2

  audio_features_in_order = ['explicit', 'duration_ms', 'danceability', 'energy',
                             'loudness', 'speechiness', 'acousticness', 'instrumentalness',
                             'liveness', 'valence', 'tempo', 'time_signature']


  # for every col ... multiply by weight
  for i in range(0, final.shape[1]):
    col_name = final.columns[i]
    split_col_name = col_name.split("|")

    # artists
    if split_col_name[0] == 'artist':
      final[col_name] = final[col_name] * song_weights[0] # artists weight

    # genres
    elif split_col_name[0] == 'genre':
      final[col_name] = final[col_name] * song_weights[1] # genre weight

    # audio_features (scalars)
    elif split_col_name[0] in audio_features_in_order:
      # get matching index in audio features
      # update based on that value
      attribute_index = audio_features_in_order.index(split_col_name[0]) # index 0 == explicit.
      target_index = attribute_index + 2 # index 2 == explicit.
      final[col_name] = final[col_name] * song_weights[target_index]  # attribute weight

    # key
    elif split_col_name[0] == 'key':
      final[col_name] = final[col_name] * song_weights[-2] # key weight

    # mode
    elif split_col_name[0] == 'mode':
      final[col_name] = final[col_name] * song_weights[-1] # mode weight

# def get_ghost_song(user_input)
# also updates weight
# assuming the second input format

# [(artists_data, weight), (genres_data, weight), (audio_feature1_explicit_data, weight), (audio_feature2_duration_ms_data, weight),
#  (audio_feature3_danceability_data, weight), ..., (audio_feature12_time_signature_data, weight), (key_data, weight), (mode_data, weight)]

# In this version, each of the audio features would have a separate tuple for its data(scalar between 0 and 1) and its own individual weight

# note for later: set final_columns_list = final.columns
# original col_list: original df.columns
def get_ghost_song(user_input, columns_list_i, columns_list_f):
  audio_features_in_order = ['explicit', 'duration_ms', 'danceability', 'energy',
                             'loudness', 'speechiness', 'acousticness', 'instrumentalness',
                             'liveness', 'valence', 'tempo', 'time_signature']


  song_attributes = [tpl[0] for tpl in user_input]  #using input v2
  song_weights = [tpl[1] for tpl in user_input]  #using input v2

  # Add weights to the attributes- todo: potentially remove or edit this part based on feedback
  # assuming that the weights are all scaled btw 0 and 1
  for i in range(0, song_attributes.len()):
    song_attributes[i] =song_attributes[i] * song_weights[i]

  # convert this list into a dataframe with the same col titles as original df
  song_df = pd.Dataframe([song_attributes], columns = columns_list_i)
  # create new empty df
  new_song_df = pd.Dataframe(columns = columns_list_f)
  # add a row of all zeros
  zero_row =[0] * len(columns_list_f)
  new_song_df = df.append(pd.DataFrame([zero_row], columns= columns_list_f, ignore_index=True))

  # update the row values based on the song
  new_song_artists = song_df['artists'].split(";")
  new_song_genres = song_df['track_genre'].split(";")
  for col_name, value in new_song_df.iloc[0].items():
    split_col_name = col_name.split("|")
    # artists
    if split_col_name[0] == 'artist':
      value = split_col_name[1] in new_song_artists # boolean artist

    # genres
    elif split_col_name[0] == 'genre':
      value = split_col_name[1] in new_song_genres # boolean genre

    # audio_features (scalars)
    elif split_col_name[0] in audio_features_in_order:
      # get matching index in audio features
      # update based on that value
      # target_index = audio_features_in_order.index(split_col_name[0]) # index 0 == explicit.
      value = song_df[split_col_name[0]]
    # key
    elif split_col_name[0] == 'key':
      value = split_col_name[0] == song_df['key']

    # mode
    elif split_col_name[0] == 'mode':
      value = split_col_name[0] == song_df['mode']

  return new_song_df

art_final.shape

# def generate_recommendations()
def generate_recommendations(df, user_df, num_recs):
  # using cosine similarity function - num recs is the number of recommendations
  # Note: this would mutate df (add/edit a similarity column)
  df['similarity'] = cosine_similarity(df.values, user_df.values)[:, 0]
  top_recs = df.sort_values('similarity', ascending = False)
  return top_recs.head(num_recs)

# combining everythnig
# have the dataset uploaded and converted to df ahead of time
def combining_everything(df, user_input, num_recs):
  # get the final dataframe
  final = get_final_attributes_and_artists(df)
  add_weights_final_df_artists(final, user_input)
  # final list of columns
  columns_list_i = df.columns
  columns_list_f = final.columns
  # get user song df
  new_song_df = get_ghost_song(user_input, columns_list_i, columns_list_f)

  # generate the recommendation
  return generate_recommendations(df, new_song_df, num_recs)

"""# Looking at some examples (optional)"""

# Optional: see how the model behaves and recommends with some examples
sample_input = [("The Weeknd", 0.3), ("pop; techno", 0.2), (False, 0), (0.7, 0), (0.8, 0.1), (0.65, 0.1), (0.5, 0), (0.5, 0), (0.1, 0.1), (0, 0), (0.3, 0.05), (0.4, 0.05), (0.6, 0.04), (0, 0), (1, 0), (1, 0.06)]

recs_df = combining_everything(df, sample_input, 10)

"""# Save model for later use (optional)"""

# Optional: put here code to save model for later use / backup
# you don't have to run this everytime and you might need to connect it to your google drive to save it

"""# Connect to frontend?"""

# any code here that we might need to get this to the front end stuff, or get the front end stuff here